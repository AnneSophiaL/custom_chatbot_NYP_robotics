{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from retrying import RetryError, retry\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from llama_index import (GPTVectorStoreIndex, LLMPredictor, PromptHelper,\n",
    "                         BeautifulSoupWebReader, SimpleDirectoryReader,\n",
    "                         load_index_from_storage, StorageContext, Document)\n",
    "from langchain import OpenAI\n",
    "\n",
    "\n",
    "def retry_if_error(exception):\n",
    "    return isinstance(exception, RetryError)\n",
    "\n",
    "\n",
    "@retry(retry_on_exception=retry_if_error, wait_fixed=1000, stop_max_attempt_number=3)\n",
    "def create_vector_index():\n",
    "    max_input = 4096\n",
    "    tokens = 256\n",
    "    chunk_size = 600\n",
    "    max_chunk_overlap = 20\n",
    "\n",
    "    prompt_helper = PromptHelper(\n",
    "        max_input, tokens, max_chunk_overlap, chunk_size_limit=chunk_size)\n",
    "\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(\n",
    "        temperature=0.5,\n",
    "        model_name=\"text-davinci-003\",\n",
    "        max_tokens=tokens\n",
    "    ))\n",
    "\n",
    "    documents = SimpleDirectoryReader(\n",
    "        'D:/ESIEE/VOYAGE SINGAP 2023/project_custom_chatbot_nyp').load_data()\n",
    "\n",
    "    vector_index = GPTVectorStoreIndex.from_documents(\n",
    "        documents=documents, llm_predictors=llm_predictor, prompt_helper=prompt_helper)\n",
    "    \n",
    "    vector_index.set_index_id(\"vector_index\")\n",
    "    vector_index.storage_context.persist('vectorIndex.json')\n",
    "\n",
    "    return vector_index\n",
    "\n",
    "\n",
    "def answer_me(vector_index):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir='vectorIndex.json')\n",
    "    v_index = load_index_from_storage(storage_context, index_id=\"vector_index\")\n",
    "\n",
    "    while True:\n",
    "        prompt = input('Please ask: ')\n",
    "        query_engine = v_index.as_query_engine()\n",
    "        response = query_engine.query(prompt)\n",
    "        print(f\"Query: {prompt} \\n\")\n",
    "        print(f\"Response: {response} \\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "    vector_index = create_vector_index()\n",
    "    answer_me(vector_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
